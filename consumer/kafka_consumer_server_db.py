# ğŸ“Œ kafka_consumer_server.py

import json
import threading
from fastapi import FastAPI
from confluent_kafka import Consumer
import hashlib
import os
from datetime import datetime
from pymongo import MongoClient

app = FastAPI()

# MongoDB ì„¤ì •
mong_client = MongoClient("mongodb://localhost:27017/")
mongo_db = mong_client["sensor_database"]
mongo_collection = mongo_db["sensor_data"]

# Kafka Consumer ì„¤ì •
conf = {
    "bootstrap.servers": "localhost:9092",
    "group.id": "sensor-group",               # ê³ ì • ê·¸ë£¹ìœ¼ë¡œ ì»¤ë°‹ ìœ ì§€
    "auto.offset.reset": "earliest",
    "enable.auto.commit": False  # ìˆ˜ë™ ì»¤ë°‹
}

consumer = Consumer(conf)
consumer.subscribe(["sensor_data"])

# ===== ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬ =====
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)

buffer = []  # ë©”ì‹œì§€ ë²„í¼
def get_log_file_path():
    """ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    today = datetime.now().strftime("%Y-%m-%d")
    return os.path.join(LOG_DIR, f"{today}.jsonl")

def write_to_file(data: dict):
    """ì„¼ì„œ ë°ì´í„°ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ íŒŒì¼ì— ì €ì¥"""
    try:
        file_path = get_log_file_path()
        with open(file_path, 'a', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False)
            f.write('\n')
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def consume_loop():
    print("ğŸ›° Kafka Consumer ìŠ¤ë ˆë“œ ì‹œì‘ë¨...")

    try:
        while True:
            message = consumer.poll(0.1)
            if message is None:
                continue
            if message.error():
                print(f"âŒ Kafka Error: {message.error()}")
                continue

            try:
                data = json.loads(message.value().decode('utf-8'))
                data["timestamp"] = datetime.fromisoformat(data.get("timestamp", "unknown"))
                buffer.append(data)

                # âœ… íŒŒì¼ ì €ì¥
                # write_to_file(data)

                if len(buffer) >= 1000:  # ë²„í¼ê°€ 1000ê°œ ì´ìƒì´ë©´
                    mongo_collection.insert_many(buffer)  # ë²„í¼ì— ìŒ“ì¸ ë°ì´í„° ì¼ê´„ ì €ì¥    
                    buffer.clear()  # ë²„í¼ ì´ˆê¸°í™”
                
                # # âœ… ìˆ˜ì‹  ë¡œê·¸ + ì¤‘ë³µ ë°©ì§€ í•´ì‹œ ì¶”ê°€
                # # âœ… ì¤‘ë³µ í™•ì¸ì„ ìœ„í•œ ë©”ì‹œì§€ SHA256 í•´ì‹œ ì¶œë ¥
                # raw_bytes = message.value()
                # digest = hashlib.sha256(raw_bytes).hexdigest()
                # print(f"{sensor_id} â†’ {value} | SHA256: {digest}")

                # âœ… ë©”ì‹œì§€ ì»¤ë°‹ (ì •ìƒ ì²˜ë¦¬ í›„)
                consumer.commit(message=message)

            except Exception as e:
                print(f"ğŸš¨ ë©”ì‹œì§€ íŒŒì‹± ì‹¤íŒ¨: {e}")

    except KeyboardInterrupt:
        print("ğŸ›‘ Kafka Consumer ì¤‘ë‹¨")
    finally:
        consumer.close()
        print("ğŸ§¹ Kafka Consumer ì •ìƒ ì¢…ë£Œ")

@app.on_event("startup")
def startup_kafka_consumer():
    thread = threading.Thread(target=consume_loop, daemon=True)
    thread.start()
    print("âœ… Kafka Consumer ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")

@app.get("/")
def root():
    return {"message": "Kafka Consumer â†’ MongoDB ì €ì¥ ì„œë²„ ì‘ë™ ì¤‘!"}
